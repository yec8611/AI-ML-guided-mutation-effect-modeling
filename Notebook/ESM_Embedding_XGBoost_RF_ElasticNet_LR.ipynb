{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.model_selection import GroupKFold, KFold, cross_val_score, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, make_scorer\n",
    "from sklearn.linear_model import ElasticNet, LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from xgboost.callback import EarlyStopping\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutations = pd.read_csv('your_path/mutations.csv') # should contain mutation string, sequence,scaled activity, and group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(model_name, sequences, device):\n",
    "    \"\"\"Generates mean-pooled embeddings for a list of sequences using a given ESM model.\"\"\"\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name).to(device)\n",
    "    model.eval()\n",
    "\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for seq in tqdm(sequences, desc=f\"Generating embeddings for {model_name}\"):\n",
    "            inputs = tokenizer(seq, return_tensors=\"pt\", truncation=True).to(device)\n",
    "            outputs = model(**inputs)\n",
    "            # Mean pooling: average the embeddings of all tokens, ignoring padding\n",
    "            attention_mask = inputs['attention_mask']\n",
    "            token_embeddings = outputs.last_hidden_state\n",
    "            masked_sum = (token_embeddings * attention_mask.unsqueeze(-1)).sum(dim=1)\n",
    "            sequence_length = attention_mask.sum(dim=1)\n",
    "            mean_pooled_embedding = masked_sum / sequence_length\n",
    "            embeddings.append(mean_pooled_embedding.cpu().numpy())\n",
    "\n",
    "    return np.vstack(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = get_embeddings(\"facebook/esm2_t33_650M_UR50D\", mutations['sequence'].tolist(), device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = embeddings\n",
    "y = mutations['scaled_activity'].values\n",
    "groups = mutations['group'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('esm_embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "def objective_xgb_final(trial):\n",
    "    params = {\n",
    "        'objective': 'reg:squarederror', 'eval_metric': 'rmse',\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 200, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'tree_method': 'hist', 'random_state': 42\n",
    "    }\n",
    "    gkf = GroupKFold(n_splits=5)\n",
    "    spearman_scores = []\n",
    "\n",
    "    for train_idx, val_idx in gkf.split(X, y, groups):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        if len(X_train) == 0 or len(X_val) == 0: continue\n",
    "\n",
    "        early_stopping_callback = EarlyStopping(rounds=50, save_best=True)\n",
    "        model = xgb.XGBRegressor(**params, callbacks=[early_stopping_callback])\n",
    "        model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "        preds = model.predict(X_val)\n",
    "        spearman_scores.append(spearmanr(y_val, preds)[0])\n",
    "\n",
    "    return np.mean(spearman_scores) if spearman_scores else -1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective_xgb_final, n_trials=50, show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "best_params = study.best_params\n",
    "best_params.update({'objective': 'reg:squarederror', 'random_state': 42, 'tree_method': 'hist'})\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "fold_metrics = []\n",
    "oof_preds = np.zeros(len(y))\n",
    "oof_true = np.zeros(len(y))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(gkf.split(X, y, groups)):\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "\n",
    "    if len(X_train) == 0 or len(X_val) == 0:\n",
    "        print(f\"Skipping Fold {fold+1} due to empty split.\")\n",
    "        continue\n",
    "\n",
    "    final_early_stopping_callback = EarlyStopping(rounds=50, save_best=True)\n",
    "    final_model = xgb.XGBRegressor(**best_params, callbacks=[final_early_stopping_callback])\n",
    "\n",
    "    final_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "\n",
    "    preds = final_model.predict(X_val)\n",
    "    oof_preds[val_idx], oof_true[val_idx] = preds, y_val\n",
    "    \n",
    "    metrics = {\n",
    "        'spearman': spearmanr(y_val, preds)[0],\n",
    "        'pearson': pearsonr(y_val, preds)[0],\n",
    "        'rmse': np.sqrt(mean_squared_error(y_val, preds)),\n",
    "        'r2': r2_score(y_val, preds)\n",
    "    }\n",
    "    fold_metrics.append(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for metric_name in fold_metrics[0].keys():\n",
    "    metric_values = [m[metric_name] for m in fold_metrics]\n",
    "    mean_val, std_val = np.mean(metric_values), np.std(metric_values)\n",
    "   \n",
    "\n",
    "\n",
    "overall_metrics = {\n",
    "    'Spearman œÅ': spearmanr(oof_true, oof_preds)[0],\n",
    "    'Pearson r ': pearsonr(oof_true, oof_preds)[0],\n",
    "    'RMSE      ': np.sqrt(mean_squared_error(oof_true, oof_preds)),\n",
    "    'R-squared ': r2_score(oof_true, oof_preds)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "def objective_rf(trial):\n",
    "    \"\"\"Optuna objective function for Random Forest Regressor.\"\"\"\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 50),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n",
    "        'max_features': trial.suggest_float('max_features', 0.1, 1.0),\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1 \n",
    "    }\n",
    "    \n",
    "    gkf = GroupKFold(n_splits=5)\n",
    "    spearman_scores = []\n",
    "\n",
    "    for train_idx, val_idx in gkf.split(X, y, groups):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        if len(X_train) == 0 or len(X_val) == 0:\n",
    "            continue\n",
    "\n",
    "        model = RandomForestRegressor(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_val)\n",
    "        spearman_scores.append(spearmanr(y_val, preds)[0])\n",
    "\n",
    "    return np.mean(spearman_scores) if spearman_scores else -1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "study_rf = optuna.create_study(direction='maximize')\n",
    "study_rf.optimize(objective_rf, n_trials=50, show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_params_rf = study_rf.best_params\n",
    "best_params_rf.update({'random_state': 42, 'n_jobs': -1})\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "fold_metrics_rf = []\n",
    "oof_preds_rf = np.zeros(len(y))\n",
    "oof_true_rf = np.zeros(len(y))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(tqdm(gkf.split(X, y, groups), total=5, desc=\"CV Folds\")):\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "    if len(X_train) == 0 or len(X_val) == 0:\n",
    "        print(f\"Skipping Fold {fold+1} due to empty split.\")\n",
    "        continue\n",
    "\n",
    "    final_model_rf = RandomForestRegressor(**best_params_rf)\n",
    "    final_model_rf.fit(X_train, y_train)\n",
    "\n",
    "    preds = final_model_rf.predict(X_val)\n",
    "    oof_preds_rf[val_idx] = preds\n",
    "    oof_true_rf[val_idx] = y_val\n",
    "    \n",
    "    metrics = {\n",
    "        'spearman': spearmanr(y_val, preds)[0],\n",
    "        'pearson': pearsonr(y_val, preds)[0],\n",
    "        'rmse': np.sqrt(mean_squared_error(y_val, preds)),\n",
    "        'r2': r2_score(y_val, preds)\n",
    "    }\n",
    "    fold_metrics_rf.append(metrics)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for metric_name in fold_metrics_rf[0].keys():\n",
    "    metric_values = [m[metric_name] for m in fold_metrics_rf]\n",
    "    mean_val, std_val = np.mean(metric_values), np.std(metric_values)\n",
    "    \n",
    "\n",
    "\n",
    "overall_metrics_rf = {\n",
    "    'Spearman œÅ': spearmanr(oof_true_rf, oof_preds_rf)[0],\n",
    "    'Pearson r ': pearsonr(oof_true_rf, oof_preds_rf)[0],\n",
    "    'RMSE      ': np.sqrt(mean_squared_error(oof_true_rf, oof_preds_rf)),\n",
    "    'R-squared ': r2_score(oof_true_rf, oof_preds_rf)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ElasticNet\n",
    "\n",
    "X = embeddings\n",
    "y = mutations['scaled_activity'].values\n",
    "groups = mutations['group'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_en(trial):\n",
    "    \"\"\"Optuna objective function for ElasticNet.\"\"\"\n",
    "\n",
    "    params = {\n",
    "        'alpha': trial.suggest_float('alpha', 1e-4, 1e1, log=True),\n",
    "        'l1_ratio': trial.suggest_float('l1_ratio', 0.0, 1.0),\n",
    "        'random_state': 42,\n",
    "        'max_iter': 2000 \n",
    "    }\n",
    "    \n",
    "    gkf = GroupKFold(n_splits=5)\n",
    "    spearman_scores = []\n",
    "\n",
    "    for train_idx, val_idx in gkf.split(X, y, groups):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        if len(X_train) == 0 or len(X_val) == 0:\n",
    "            continue\n",
    "\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "        model = ElasticNet(**params)\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        preds = model.predict(X_val_scaled)\n",
    "        spearman_scores.append(spearmanr(y_val, preds)[0])\n",
    "\n",
    "    return np.mean(spearman_scores) if spearman_scores else -1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "study_en = optuna.create_study(direction='maximize')\n",
    "\n",
    "study_en.optimize(objective_en, n_trials=50, show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_params_en = study_en.best_params\n",
    "best_params_en.update({'random_state': 42, 'max_iter': 2000})\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "fold_metrics_en = []\n",
    "oof_preds_en = np.zeros(len(y))\n",
    "oof_true_en = np.zeros(len(y))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(tqdm(gkf.split(X, y, groups), total=5, desc=\"CV Folds\")):\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "    if len(X_train) == 0 or len(X_val) == 0:\n",
    "        continue\n",
    "\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    final_model_en = ElasticNet(**best_params_en)\n",
    "    final_model_en.fit(X_train_scaled, y_train)\n",
    "\n",
    "    preds = final_model_en.predict(X_val_scaled)\n",
    "    oof_preds_en[val_idx] = preds\n",
    "    oof_true_en[val_idx] = y_val\n",
    "    \n",
    "    metrics = {\n",
    "        'spearman': spearmanr(y_val, preds)[0],\n",
    "        'pearson': pearsonr(y_val, preds)[0],\n",
    "        'rmse': np.sqrt(mean_squared_error(y_val, preds)),\n",
    "        'r2': r2_score(y_val, preds)\n",
    "    }\n",
    "    fold_metrics_en.append(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for metric_name in fold_metrics_en[0].keys():\n",
    "    metric_values = [m[metric_name] for m in fold_metrics_en]\n",
    "    mean_val, std_val = np.mean(metric_values), np.std(metric_values)\n",
    "    \n",
    "\n",
    "\n",
    "overall_metrics_en = {\n",
    "    'Spearman œÅ': spearmanr(oof_true_en, oof_preds_en)[0],\n",
    "    'Pearson r ': pearsonr(oof_true_en, oof_preds_en)[0],\n",
    "    'RMSE      ': np.sqrt(mean_squared_error(oof_true_en, oof_preds_en)),\n",
    "    'R-squared ': r2_score(oof_true_en, oof_preds_en)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "fold_metrics_lr = []\n",
    "oof_preds_lr = np.zeros(len(y))\n",
    "oof_true_lr = np.zeros(len(y))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(tqdm(gkf.split(X, y, groups), total=5, desc=\"CV Folds\")):\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "    if len(X_train) == 0 or len(X_val) == 0:\n",
    "        continue\n",
    "\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "   \n",
    "    final_model_lr = LinearRegression()\n",
    "    final_model_lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "    preds = final_model_lr.predict(X_val_scaled)\n",
    "    oof_preds_lr[val_idx] = preds\n",
    "    oof_true_lr[val_idx] = y_val\n",
    "    \n",
    "    metrics = {\n",
    "        'spearman': spearmanr(y_val, preds)[0],\n",
    "        'pearson': pearsonr(y_val, preds)[0],\n",
    "        'rmse': np.sqrt(mean_squared_error(y_val, preds)),\n",
    "        'r2': r2_score(y_val, preds)\n",
    "    }\n",
    "    fold_metrics_lr.append(metrics)\n",
    "\n",
    "\n",
    "\n",
    "for metric_name in fold_metrics_lr[0].keys():\n",
    "    metric_values = [m[metric_name] for m in fold_metrics_lr]\n",
    "    mean_val, std_val = np.mean(metric_values), np.std(metric_values)\n",
    "    \n",
    "\n",
    "\n",
    "overall_metrics_lr = {\n",
    "    'Spearman œÅ': spearmanr(oof_true_lr, oof_preds_lr)[0],\n",
    "    'Pearson r ': pearsonr(oof_true_lr, oof_preds_lr)[0],\n",
    "    'RMSE      ': np.sqrt(mean_squared_error(oof_true_lr, oof_preds_lr)),\n",
    "    'R-squared ': r2_score(oof_true_lr, oof_preds_lr)\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openfold-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
